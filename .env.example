# LLM provider settings
OPENAI_API_KEY=
OPENAI_MODEL=gpt-3.5-turbo

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2048
LLM_TIMEOUT=30

# Runtime switches
USE_MOCK_API=false

# Chainlit / FastAPI (optional overrides)
DEFAULT_LLM_PROVIDER=mock
